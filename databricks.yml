# This is a Databricks asset bundle definition for lakeflow_complaints_pipeline.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.
bundle:
  name: lakeflow_complaints_pipeline

include:
  - resources/*.yml
  - resources/*/*.yml

# Variable declarations. These variables are assigned in the dev/prod targets below.

targets:
  dev:
    # The default target uses 'mode: development' to create a development copy.
    # - Deployed resources get prefixed with '[dev]' (custom prefix)
    # - Any job schedules and triggers are paused by default (Develop Mode)
    # See also https://docs.databricks.com/dev-tools/bundles/deployment-modes.html.
    mode: development
    default: true
    workspace:
      host: https://adb-984752964297111.11.azuredatabricks.net
      # We explicitly deploy to /Workspace/Users/user@company.com to make sure we only have a single copy
      root_path: /Workspace/Users/daniel.zoccali@databricks.com/.bundle/${bundle.name}/${bundle.target}
    
    # Custom prefix for dev resources (includes username for uniqueness in development mode)
    presets:
      name_prefix: "[dev_${workspace.current_user.short_name}]"
    
    variables:
      catalog: dz_demos_dev
      schema: ${workspace.current_user.short_name}
      volume_path: /Volumes/dz_demos_dev/lakeflow_dec_pipe_r_scripts/demo_source_data
      # Dev uses all-purpose cluster (not serverless)
      pipeline_serverless: false
      # Dev environment tags
      environment_tags:
        Environment: "development"
        Project: "lakeflow_complaints_demo"
        Owner: "daniel.zoccali@databricks.com"
        CostCenter: "engineering"
    
    # Dev-specific resource overrides
    resources:
      pipelines:
        customer_complaints_pipeline:
          # Add cluster configuration for dev environment (all-purpose clusters)
          clusters:
            - node_type_id: "Standard_D8s_v3"
              driver_node_type_id: "Standard_D8s_v3"
              num_workers: 2
              spark_conf:
                "spark.databricks.delta.preview.enabled": "true"
                "spark.sql.adaptive.enabled": "true"
                "spark.sql.adaptive.coalescePartitions.enabled": "true"
              custom_tags: ${var.environment_tags}
      
  prod:
    mode: production
    workspace:
      host: https://adb-984752964297111.11.azuredatabricks.net #  For this demo, it is the same workspace
      # We explicitly deploy to /Workspace/Users/user@company.com to make sure we only have a single copy
      root_path: /Workspace/Prod/.bundle/${bundle.name}/${bundle.target}
    
    # Run production pipeline as service principal
    run_as:
      service_principal_name: 45d38527-d29d-4e63-8cbb-0608e7472025
    
    variables:
      catalog: dz_demos
      schema: lakeflow_dec_pipe_r_scripts
      volume_path: /Volumes/dz_demos/lakeflow_dec_pipe_r_scripts/demo_source_data
      # Prod uses job clusters (serverless compute)
      pipeline_serverless: true
      # Production environment tags
      environment_tags:
        Environment: "production"
        Project: "lakeflow_complaints_demo"
        Owner: "daniel.zoccali@databricks.com"
        CostCenter: "business"
        Criticality: "high"
    
    permissions:
      - user_name: daniel.zoccali@databricks.com
        level: CAN_MANAGE
      - service_principal_name: 45d38527-d29d-4e63-8cbb-0608e7472025
        level: CAN_MANAGE

# Variables that can be referenced throughout the bundle
variables:
  catalog:
    description: Unity Catalog catalog name
    default: dz_demos
  
  schema:
    description: Unity Catalog schema name
    default: lakeflow_dec_pipe_r_scripts
  
  volume_path:
    description: Path to source data volume
    default: /Volumes/dz_demos/lakeflow_dec_pipe_r_scripts/demo_source_data
  
  # Environment-specific compute configuration
  pipeline_serverless:
    description: Whether to use serverless compute for pipeline
    default: false
  
  # Environment tags for resource tracking
  environment_tags:
    description: Tags to apply to all resources
    default:
      Environment: "unknown"
      Project: "lakeflow_complaints_demo"
      Owner: "daniel.zoccali@databricks.com"

